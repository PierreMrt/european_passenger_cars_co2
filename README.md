# Analyse des Ã‰missions de COâ‚‚ des Voitures EuropÃ©ennes

Identifier les vÃ©hicules qui Ã©mettent le plus de CO2 est important pour identifier les caractÃ©ristiques techniques qui jouent un rÃ´le dans la pollution. PrÃ©dire Ã  lâ€™avance cette pollution permet de prÃ©venir dans le cas de lâ€™apparition de nouveaux types de vÃ©hicules (nouvelles sÃ©ries de voitures par exemple).

Ce projet vise donc Ã  analyser et modÃ©liser les Ã©missions de COâ‚‚ des voitures europÃ©ennes en utilisant des techniques de **prÃ©traitement des donnÃ©es**, **d'ingÃ©nierie des caractÃ©ristiques**, et de **modÃ©lisation machine learning**.

---

## Table des MatiÃ¨res

- [DonnÃ©es UtilisÃ©es](#donnÃ©es-utilisÃ©es)
- [Structure du Projet](#structure-du-projet)
- [Description des Fichiers](#description-des-fichiers)
  - [data_reduction.py](#data_reductionpy)
  - [preprocessing.py](#preprocessingpy)
  - [feature_engineering.py](#feature_engineeringpy)
  - [pipeline.py](#pipelinepy)
- [Installation](#installation)
  - [PrÃ©requis](#prÃ©requis)
  - [Configuration de l'Environnement](#configuration-de-lenvironnement)
- [Utilisation](#utilisation)
  - [Pipeline ComplÃ¨te](#lancer-la-pipeline-complÃ¨te)
  - [Ã‰tapes Individuelles](#lancer-les-Ã©tapes-individuelles)
- [Application Streamlit](#application-streamlit)
  - [Exploration](#-exploration)
  - [RÃ©sultats](#-rÃ©sultats)
  - [PrÃ©diction](#-prÃ©diction)
- [RÃ©sultats et MÃ©thodologie](#rÃ©sultats-et-mÃ©thodologie-du-modÃ¨le)
  - [StratÃ©gie de ModÃ©lisation](#stratÃ©gie-de-modÃ©lisation)
  - [HyperparamÃ¨tres](#hyperparamÃ¨tres-du-modÃ¨le)
  - [Feature Engineering](#feature-engineering)
  - [Validation CroisÃ©e](#stratÃ©gie-de-validation-croisÃ©e)
  - [MÃ©triques de Performance](#mÃ©triques-de-performance)
  - [Variables Influentes](#variables-les-plus-influentes)
  - [Utilisation du ModÃ¨le](#chargement-du-modÃ¨le)

---

## DonnÃ©es utilisÃ©es

Le jeu de donnÃ©es utilisÃ© est le suivant, en prenant les vÃ©hicules belges, franÃ§ais et allemand, immatriculÃ©s entre 2022 et 2024:

https://www.eea.europa.eu/en/datahub/datahubitem-view/fa8b1229-3db6-495d-b18e-9c9b3267c02b


## Structure du Projet

```
european_passenger_cars_co2/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ data_processed.csv              # DonnÃ©es prÃ©traitÃ©es
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ *.ipynb                         # Notebooks de travail et d'exploration des donnÃ©es
â”‚
â”œâ”€â”€ fig/
â”‚   â”œâ”€â”€ *.csv                           # MÃ©triques des diffÃ©rents modÃ¨les
â”‚   â””â”€â”€ *.html                          # Figures et graphiques interactifs (Plotly)
â”‚
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ training.log                    # Logs des entraÃ®nements de modÃ¨les
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ random_forest_model.jbl.lzma    # ModÃ¨le entraÃ®nÃ© sauvegardÃ© (compressÃ©)
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ data_reduction.py               # RÃ©duction et nettoyage des donnÃ©es brutes
â”‚   â”œâ”€â”€ feature_engineering.py          # IngÃ©nierie des caractÃ©ristiques
â”‚   â”œâ”€â”€ pipeline.py                     # Pipeline de modÃ©lisation complÃ¨te
â”‚   â””â”€â”€ preprocessing.py                # PrÃ©traitement des donnÃ©es
â”‚
â”œâ”€â”€ streamlit_app/
â”‚   â”œâ”€â”€ pages/                          
â”‚   â”‚   â”œâ”€â”€ exploration.py              # Page d'exploration des donnÃ©es
â”‚   â”‚   â”œâ”€â”€ predict.py                  # Page de prÃ©diction interactive
â”‚   â”‚   â””â”€â”€ results.py                  # Page d'analyse des rÃ©sultats des modÃ¨les
â”‚   â”œâ”€â”€ utils/                          
â”‚   â”‚   â”œâ”€â”€ data_loaders.py             # Chargement des donnÃ©es
â”‚   â”‚   â”œâ”€â”€ model_utils.py              # Utilitaires pour les modÃ¨les
â”‚   â”‚   â””â”€â”€ viz_tools.py                # Outils de visualisation
â”‚   â”œâ”€â”€ app.py                          # Application principale Streamlit
â”‚   â””â”€â”€ make_graphs.py                  # GÃ©nÃ©ration des graphiques pour Streamlit (stockÃ©s dans fig/)
â”‚
â”œâ”€â”€ .gitattributes                      # Configuration pour Git LFS
â”œâ”€â”€ .gitignore                          # Fichiers Ã  ignorer par Git
â”œâ”€â”€ LICENSE                             # Licence du projet (MIT)
â”œâ”€â”€ README.md                           # Documentation du projet
â”œâ”€â”€ requirements.txt                    # DÃ©pendances Python du projet
â””â”€â”€ Table-definition.xlsx               # DÃ©finition des colonnes du dataset
```

---

## Description des Fichiers

### `data_reduction.py`
Ce script est responsable de la **rÃ©duction et du nettoyage des donnÃ©es brutes**. Il inclut les fonctionnalitÃ©s suivantes :
- Suppression des doublons.
- Gestion des valeurs manquantes.
- SÃ©lection des colonnes pertinentes pour l'analyse.

---

### `preprocessing.py`
Ce script est dÃ©diÃ© au **nettoyage et prÃ©traitement des donnÃ©es** avant leur utilisation dans un modÃ¨le de machine learning. Il inclut plusieurs Ã©tapes essentielles :
- Nettoyage des noms de colonnes et des valeurs des donnÃ©es.
- Conversion des dates en caractÃ©ristiques numÃ©riques (comme l'Ã¢ge des vÃ©hicules).
- Suppression des valeurs aberrantes et gestion des valeurs manquantes.
- Normalisation des noms de fabricants et des types de carburant.

Ce script prÃ©pare les donnÃ©es brutes pour qu'elles soient prÃªtes Ã  Ãªtre utilisÃ©es dans les Ã©tapes suivantes d'ingÃ©nierie des caractÃ©ristiques et de modÃ©lisation.


---

### `feature_engineering.py`
Ce script est responsable de **l'ingÃ©nierie des caractÃ©ristiques** en utilisant `ColumnTransformer` de scikit-learn. Il dÃ©finit les transformations Ã  appliquer aux diffÃ©rentes colonnes des donnÃ©es :
- Normalisation et mise Ã  l'Ã©chelle des caractÃ©ristiques numÃ©riques (comme la cylindrÃ©e, la puissance, la masse, et l'Ã¢ge des vÃ©hicules).
- Encodage des caractÃ©ristiques catÃ©gorielles (comme le type de carburant).

Ce transformateur est conÃ§u pour Ãªtre intÃ©grÃ© dans un pipeline scikit-learn afin de prÃ©parer les donnÃ©es pour l'entraÃ®nement du modÃ¨le.

---

### `pipepline.py`
Ce script contient le **pipeline complet** pour entraÃ®ner et Ã©valuer un modÃ¨le de machine learning. Il utilise :
- argparse pour la modularitÃ©
- Un pipeline scikit-learn pour enchaÃ®ner les Ã©tapes de feature engineering et de modÃ©lisation.
- Validation croisÃ©e pour Ã©valuer les performances du modÃ¨le.
- Sauvegarde du modÃ¨le entraÃ®nÃ©.

---

## PrÃ©requis

Pour exÃ©cuter ce projet, vous aurez besoin des bibliothÃ¨ques Python suivantes :
- `pandas`
- `numpy`
- `scikit-learn`
- `shap`
- `joblib`
- `plotly`
- `streamlit`


CrÃ©ez un environnement virtuel :
```bash
python -m venv .venv
```

Activez le :
- Sur windows : `source .venv/Script/activate`
- Sur linux/Mac : `source .venv/bin/activate`

Installez-les avec la commande suivante :
```bash
pip install -r requirements.txt
```

---

## Utilisation

### Lancer la pipeline complÃ¨te

La pipeline peut Ãªtre exÃ©cutÃ©e en une seule commande avec diffÃ©rents points de dÃ©part :

- **Ã€ partir des donnÃ©es brutes** (exÃ©cute toutes les Ã©tapes : rÃ©duction, prÃ©traitement, entraÃ®nement) :
  ```bash
  python scripts/pipeline.py --start-from raw
  ```

- **Ã€ partir des donnÃ©es rÃ©duites** (exÃ©cute le prÃ©traitement et l'entraÃ®nement) :
  ```bash
  python scripts/pipeline.py --start-from reduced
  ```

- **Ã€ partir des donnÃ©es prÃ©traitÃ©es** (exÃ©cute uniquement l'entraÃ®nement) :
  ```bash
  python scripts/pipeline.py --start-from preprocessed
  ```

### Lancer les Ã©tapes individuelles

Les Ã©tapes de la pipeline peuvent Ã©galement Ãªtre exÃ©cutÃ©es individuellement:

1. **PrÃ©traitement des donnÃ©es** :
   ExÃ©cutez le script `data_reduction.py` pour nettoyer et rÃ©duire les donnÃ©es brutes :
   ```bash
   python scripts/data_reduction.py
   ```

2. **IngÃ©nierie des caractÃ©ristiques** :
   ExÃ©cutez le script `preprocessing.py` pour nettoyer et gÃ©rer les valeurs manquantes :
   ```bash
   python scripts/preprocessing.py
   ```

3. **EntraÃ®nement du modÃ¨le** :
   ExÃ©cutez le script `pipeline.py` pour entraÃ®ner le modÃ¨le et sauvegarder les rÃ©sultats (Ã©quivalent Ã  `--start-from preprocessed`) :
   ```bash
   python scripts/pipeline.py
   ```

### Remarques

- Assurez-vous que les fichiers de donnÃ©es nÃ©cessaires (`data.csv`, `data_processed.csv`, etc.) sont prÃ©sents dans le rÃ©pertoire `data/` avant de lancer les scripts.
- Les rÃ©sultats intermÃ©diaires et finaux seront sauvegardÃ©s dans les rÃ©pertoires `data/` et `models/`.


---

## Application Streamlit

L'application Streamlit offre une interface interactive permettant d'explorer et d'analyser les Ã©missions de COâ‚‚ des voitures europÃ©ennes. Elle se compose de trois pages principales :

#### ğŸ“Š Exploration
Analyse exploratoire du jeu de donnÃ©es brut avant traitement, comprenant :
- **Taux de complÃ©tion des colonnes** : Visualisation du pourcentage de valeurs renseignÃ©es pour identifier les colonnes nÃ©cessitant un nettoyage
- **RÃ©partition des types de carburant** : Distribution des vÃ©hicules selon leur carburant pour identifier les types dominants
- **Distribution de la puissance par carburant** : DÃ©tection des outliers (vÃ©hicules de sport) qui pourraient biaiser le modÃ¨le
- **Relation cylindrÃ©e vs Ã©missions** : CorrÃ©lation entre cylindrÃ©e et COâ‚‚ avec lignes de rÃ©gression par type de carburant
- **Matrice de corrÃ©lation** : Relations linÃ©aires entre caractÃ©ristiques techniques

#### ğŸ“ˆ RÃ©sultats
Analyse comparative des modÃ¨les de prÃ©diction avec trois sections :
- **Classification K-means** : Regroupement des vÃ©hicules par caractÃ©ristiques similaires (analyse exploratoire)
- **RÃ©gression linÃ©aire vs Random Forest (avec consommation)** : Comparaison des performances et identification de la forte corrÃ©lation entre consommation et Ã©missions
- **Random Forest sans consommation** : Comparaison avec/sans feature engineering pour analyser l'influence rÃ©elle des variables techniques (cylindrÃ©e, puissance, masse, Ã¢ge)

#### ğŸ”® PrÃ©diction
Outil interactif permettant de saisir les caractÃ©ristiques d'un vÃ©hicule et d'obtenir une prÃ©diction des Ã©missions de COâ‚‚ via le modÃ¨le Random Forest entraÃ®nÃ©

Pour lancer l'application :

``` bash
streamlit run streamlit_app/app.py
```

---


## RÃ©sultats et MÃ©thodologie du ModÃ¨le

### StratÃ©gie de ModÃ©lisation

Le modÃ¨le Random Forest a Ã©tÃ© sÃ©lectionnÃ© aprÃ¨s une analyse comparative de plusieurs approches de rÃ©gression (rÃ©gression linÃ©aire, Random Forest avec/sans consommation de carburant). Le choix final s'est portÃ© sur Random Forest **sans consommation de carburant** mais **avec feature engineering** pour les raisons suivantes :

- **Objectif prÃ©dictif** : Permet d'estimer les Ã©missions avant la connaissance de la consommation rÃ©elle
- **InterprÃ©tabilitÃ©** : Identifie l'influence rÃ©elle des caractÃ©ristiques techniques du vÃ©hicule
- **Robustesse** : GÃ¨re efficacement les relations non-linÃ©aires entre variables
- **Performance** : Atteint une prÃ©cision Ã©levÃ©e tout en Ã©vitant le surapprentissage

### HyperparamÃ¨tres du ModÃ¨le

Le modÃ¨le Random Forest final utilise les hyperparamÃ¨tres suivants :

``` python
RandomForestRegressor(
  n_estimators=100,     # Nombre d'arbres dans la forÃªt
  max_depth=20,         # Profondeur maximale des arbres
  min_samples_split=5,  # Ã‰chantillons minimum pour diviser un nÅ“ud
  min_samples_leaf=1,   # Ã‰chantillons minimum dans une feuille
  bootstrap=True,       # Bootstrap des Ã©chantillons
  random_state=42       # ReproductibilitÃ©
)
```

Ces hyperparamÃ¨tres ont Ã©tÃ© sÃ©lectionnÃ©s Ã  l'aide d'une GridSearch (cf `notebooks/model_creation.ipynb`).

### Feature Engineering

Les transformations appliquÃ©es aux variables sont dÃ©finies dans un `ColumnTransformer` intÃ©grÃ© au pipeline :

| Variable | Transformation | Justification |
|----------|---------------|---------------|
| **ec (cm3)** | StandardScaler | Normalisation de la cylindrÃ©e (distribution gaussienne) |
| **ep (KW)** | StandardScaler | Normalisation de la puissance (distribution gaussienne) |
| **m (kg)** | StandardScaler | Normalisation de la masse (large plage de valeurs) |
| **age_months** | MinMaxScaler | Mise Ã  l'Ã©chelle [0,1] de l'Ã¢ge (croissance monotone) |
| **Ft (type carburant)** | OneHotEncoder | Encodage catÃ©goriel avec gestion des valeurs inconnues |

Ces transformations permettent :
- D'uniformiser les Ã©chelles pour Ã©viter la dominance de certaines variables
- De gÃ©rer correctement les variables catÃ©gorielles
- De maintenir l'interprÃ©tabilitÃ© du modÃ¨le via SHAP

### StratÃ©gie de Validation CroisÃ©e

La mÃ©thodologie d'Ã©valuation suit un protocole en trois Ã©tapes :

#### 1. Division Train/Test
- **Ratio** : 80% entraÃ®nement / 20% test
- **Stratification** : AlÃ©atoire avec `random_state=42` pour reproductibilitÃ©
- **Objectif** : Conserver un ensemble de test intact pour Ã©valuation finale

#### 2. Validation CroisÃ©e (5-Fold)

``` python
cross_validate(
pipeline, X_train, y_train,
cv=5, # 5 plis
scoring={
"neg_mse": make_scorer(mean_squared_error, greater_is_better=False),
"r2": "r2"
},
return_train_score=True, # Calcul des scores d'entraÃ®nement
n_jobs=-1 # ParallÃ©lisation
)
```

- **5 folds** : Chaque observation sert Ã  l'entraÃ®nement et Ã  la validation
- **MÃ©triques doubles** : MSE (erreur absolue) et RÂ² (coefficient de dÃ©termination)
- **DÃ©tection du surapprentissage** : Comparaison train/validation scores


#### 3. Ã‰valuation Finale sur Test Set
- **DonnÃ©es jamais vues** : Le modÃ¨le est Ã©valuÃ© sur les 20% de donnÃ©es test
- **MÃ©triques finales** : MSE et RÂ² calculÃ©s sur des prÃ©dictions hors Ã©chantillon

### MÃ©triques de Performance

| Ensemble | MSE (g/km) | RÂ² | RMSE (g/km) |
|----------|------------|-----|-------------|
| **EntraÃ®nement (CV)** | 24,05 | 0,9866 | 4,90 |
| **Validation croisÃ©e** | 34,98 | 0,9805 | 5,91 |
| **Test** | 32,70 | 0,9816 | 5,72 |

**InterprÃ©tation des rÃ©sultats** :
- **RÂ² = 0,9816** : Le modÃ¨le explique 98,16% de la variance des Ã©missions de COâ‚‚
- **RMSE = 5,72 g/km** : Erreur moyenne de prÃ©diction faible
- **Ã‰cart train/test minimal** : Pas de surapprentissage significatif (diffÃ©rence de 1,2% sur RÂ²)
- **GÃ©nÃ©ralisation robuste** : Performances cohÃ©rentes entre validation croisÃ©e et test

### Variables les Plus Influentes

L'analyse SHAP (SHapley Additive exPlanations) rÃ©vÃ¨le l'importance relative des features :

1. **Type de carburant (Ft)** : Impact majeur, particuliÃ¨rement pour les hybrides
2. **Masse du vÃ©hicule (m)** : CorrÃ©lation positive forte avec les Ã©missions
3. **CylindrÃ©e (ec)** : Indicateur clÃ© de la consommation potentielle
4. **Puissance (ep)** : Influence modÃ©rÃ©e
5. **Ã‚ge (age_months)** : Impact mineur

Les graphiques SHAP dÃ©taillÃ©s sont disponibles dans l'application Streamlit (page **RÃ©sultats**).

### Pipeline Complet

Le pipeline scikit-learn intÃ¨gre toutes les transformations et le modÃ¨le :

``` python
Pipeline([
  ('features', ColumnTransformer([...])), # Feature engineering
  ('model', RandomForestRegressor(...))   # ModÃ¨le
])
```

**Avantages** :
- Pas de fuite de donnÃ©es (data leakage) entre train et test
- Transformations appliquÃ©es automatiquement lors de `.predict()`
- ReproductibilitÃ© garantie
- FacilitÃ© de dÃ©ploiement

### Chargement du ModÃ¨le

Le modÃ¨le entraÃ®nÃ© peut Ãªtre chargÃ© pour faire des prÃ©dictions :

``` python
import joblib
import pandas as pd

# Chargement du pipeline complet
model = joblib.load('models/random_forest_model.jbl.lzma')

# PrÃ©diction (les transformations sont appliquÃ©es automatiquement)
new_vehicle = pd.DataFrame({
    'm (kg)': [1500],
    'Ft': ['Petrol'],
    'ec (cm3)': [1600],
    'ep (KW)': [110],
    'age_months': [12]
})

predicted_co2 = model.predict(new_vehicle)
print(f"Ã‰missions prÃ©dites : {predicted_co2[0]:.2f} g/km")
```

---

## Contribuer

Les contributions sont les bienvenues ! Pour contribuer :
1. Fork ce dÃ©pÃ´t.
2. CrÃ©ez une branche pour votre fonctionnalitÃ© (`git checkout -b feature/ma-nouvelle-fonctionnalite`).
3. Commitez vos modifications (`git commit -am 'Ajout d'une nouvelle fonctionnalitÃ©'`).
4. Poussez la branche (`git push origin feature/ma-nouvelle-fonctionnalite`).
5. Ouvrez une Pull Request.

---

## Licence

Ce projet est sous licence MIT. Voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.
