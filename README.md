# Analyse des Ã‰missions de COâ‚‚ des Voitures EuropÃ©ennes

Identifier les vÃ©hicules qui Ã©mettent le plus de CO2 est important pour identifier les caractÃ©ristiques techniques qui jouent un rÃ´le dans la pollution. PrÃ©dire Ã  lâ€™avance cette pollution permet de prÃ©venir dans le cas de lâ€™apparition de nouveaux types de vÃ©hicules (nouvelles sÃ©ries de voitures par exemple).

Ce projet vise donc Ã  analyser et modÃ©liser les Ã©missions de COâ‚‚ des voitures europÃ©ennes en utilisant des techniques de **prÃ©traitement des donnÃ©es**, **d'ingÃ©nierie des caractÃ©ristiques**, et de **modÃ©lisation machine learning**.

---

## Table des MatiÃ¨res

- [Jeu de donnÃ©es](#donnÃ©es-utilisÃ©es)
- [Structure du Projet](#structure-du-projet)
- [Description des Fichiers](#description-des-fichiers)
  - [`data_reduction.py`](#data_reductionpy)
  - [`preprocessing.py`](#preprocessingpy)
  - [`feature_engineering.py`](#feature_engineeringpy)
  - [`pipepline.py`](#pipeplinepy)
- [PrÃ©requis](#prÃ©requis)
- [Utilisation](#utilisation)
- [Streamlit](#application-streamlit)
- [RÃ©sultats](#rÃ©sultats-du-modÃ¨le)

---

## DonnÃ©es utilisÃ©es

Le jeu de donnÃ©es utilisÃ© est le suivant, en prenant les vÃ©hicules belges, franÃ§ais et allemand, immatriculÃ©s entre 2022 et 2024:

https://www.eea.europa.eu/en/datahub/datahubitem-view/fa8b1229-3db6-495d-b18e-9c9b3267c02b


## Structure du Projet

```
european_passenger_cars_co2/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ data_processed.csv              # DonnÃ©es prÃ©traitÃ©es
â”‚
â”œâ”€â”€ exploration/
â”‚   â””â”€â”€ *.ipynb                         # Notebooks de travail et d'exploration des donnÃ©es
â”‚
â”œâ”€â”€ fig/
â”‚   â”œâ”€â”€ *.csv                           # MÃ©triques des diffÃ©rents modÃ¨les
â”‚   â””â”€â”€ *.html                          # Figures et graphiques interactifs (Plotly)
â”‚
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ training.log                    # Logs des entraÃ®nements de modÃ¨les
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ random_forest_model.jbl.lzma    # ModÃ¨le entraÃ®nÃ© sauvegardÃ© (compressÃ©)
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ data_reduction.py               # RÃ©duction et nettoyage des donnÃ©es brutes
â”‚   â”œâ”€â”€ feature_engineering.py          # IngÃ©nierie des caractÃ©ristiques
â”‚   â”œâ”€â”€ pipeline.py                     # Pipeline de modÃ©lisation complÃ¨te
â”‚   â””â”€â”€ preprocessing.py                # PrÃ©traitement des donnÃ©es
â”‚
â”œâ”€â”€ streamlit_app/
â”‚   â”œâ”€â”€ pages/                          
â”‚   â”‚   â”œâ”€â”€ exploration.py              # Page d'exploration des donnÃ©es
â”‚   â”‚   â”œâ”€â”€ predict.py                  # Page de prÃ©diction interactive
â”‚   â”‚   â””â”€â”€ results.py                  # Page d'analyse des rÃ©sultats des modÃ¨les
â”‚   â”œâ”€â”€ utils/                          
â”‚   â”‚   â”œâ”€â”€ data_loaders.py             # Chargement des donnÃ©es
â”‚   â”‚   â”œâ”€â”€ model_utils.py              # Utilitaires pour les modÃ¨les
â”‚   â”‚   â””â”€â”€ viz_tools.py                # Outils de visualisation
â”‚   â”œâ”€â”€ app.py                          # Application principale Streamlit
â”‚   â””â”€â”€ make_graphs.py                  # GÃ©nÃ©ration des graphiques pour Streamlit (stockÃ©s dans fig/)
â”‚
â”œâ”€â”€ .gitattributes                      # Configuration pour Git LFS
â”œâ”€â”€ .gitignore                          # Fichiers Ã  ignorer par Git
â”œâ”€â”€ LICENSE                             # Licence du projet (MIT)
â”œâ”€â”€ README.md                           # Documentation du projet
â”œâ”€â”€ requirements.txt                    # DÃ©pendances Python du projet
â””â”€â”€ Table-definition.xlsx               # DÃ©finition des colonnes du dataset
```

---

## Description des Fichiers

### `data_reduction.py`
Ce script est responsable de la **rÃ©duction et du nettoyage des donnÃ©es brutes**. Il inclut les fonctionnalitÃ©s suivantes :
- Suppression des doublons.
- Gestion des valeurs manquantes.
- SÃ©lection des colonnes pertinentes pour l'analyse.

---

### `preprocessing.py`
Ce script est dÃ©diÃ© au **nettoyage et prÃ©traitement des donnÃ©es** avant leur utilisation dans un modÃ¨le de machine learning. Il inclut plusieurs Ã©tapes essentielles :
- Nettoyage des noms de colonnes et des valeurs des donnÃ©es.
- Conversion des dates en caractÃ©ristiques numÃ©riques (comme l'Ã¢ge des vÃ©hicules).
- Suppression des valeurs aberrantes et gestion des valeurs manquantes.
- Normalisation des noms de fabricants et des types de carburant.

Ce script prÃ©pare les donnÃ©es brutes pour qu'elles soient prÃªtes Ã  Ãªtre utilisÃ©es dans les Ã©tapes suivantes d'ingÃ©nierie des caractÃ©ristiques et de modÃ©lisation.


---

### `feature_engineering.py`
Ce script est responsable de **l'ingÃ©nierie des caractÃ©ristiques** en utilisant `ColumnTransformer` de scikit-learn. Il dÃ©finit les transformations Ã  appliquer aux diffÃ©rentes colonnes des donnÃ©es :
- Normalisation et mise Ã  l'Ã©chelle des caractÃ©ristiques numÃ©riques (comme la cylindrÃ©e, la puissance, la masse, et l'Ã¢ge des vÃ©hicules).
- Encodage des caractÃ©ristiques catÃ©gorielles (comme le type de carburant).

Ce transformateur est conÃ§u pour Ãªtre intÃ©grÃ© dans un pipeline scikit-learn afin de prÃ©parer les donnÃ©es pour l'entraÃ®nement du modÃ¨le.

---

### `pipepline.py`
Ce script contient le **pipeline complet** pour entraÃ®ner et Ã©valuer un modÃ¨le de machine learning. Il utilise :
- argparse pour la modularitÃ©
- Un pipeline scikit-learn pour enchaÃ®ner les Ã©tapes de feature engineering et de modÃ©lisation.
- Validation croisÃ©e pour Ã©valuer les performances du modÃ¨le.
- Sauvegarde du modÃ¨le entraÃ®nÃ©.

---

## PrÃ©requis

Pour exÃ©cuter ce projet, vous aurez besoin des bibliothÃ¨ques Python suivantes :
- `pandas`
- `numpy`
- `scikit-learn`
- `shap`
- `joblib`
- `plotly`
- `streamlit`


CrÃ©ez un environnement virtuel :
```bash
python -m venv .venv
```

Activez le :
- Sur windows : `source .venv/Script/activate`
- Sur linux/Mac : `source .venv/bin/activate`

Installez-les avec la commande suivante :
```bash
pip install -r requirements.txt
```

---

## Utilisation

### Lancer la pipeline complÃ¨te

La pipeline peut Ãªtre exÃ©cutÃ©e en une seule commande avec diffÃ©rents points de dÃ©part :

- **Ã€ partir des donnÃ©es brutes** (exÃ©cute toutes les Ã©tapes : rÃ©duction, prÃ©traitement, entraÃ®nement) :
  ```bash
  python scripts/pipeline.py --start-from raw
  ```

- **Ã€ partir des donnÃ©es rÃ©duites** (exÃ©cute le prÃ©traitement et l'entraÃ®nement) :
  ```bash
  python scripts/pipeline.py --start-from reduced
  ```

- **Ã€ partir des donnÃ©es prÃ©traitÃ©es** (exÃ©cute uniquement l'entraÃ®nement) :
  ```bash
  python scripts/pipeline.py --start-from preprocessed
  ```

### Lancer les Ã©tapes individuelles

Les Ã©tapes de la pipeline peuvent Ã©galement Ãªtre exÃ©cutÃ©es individuellement:

1. **PrÃ©traitement des donnÃ©es** :
   ExÃ©cutez le script `data_reduction.py` pour nettoyer et rÃ©duire les donnÃ©es brutes :
   ```bash
   python scripts/data_reduction.py
   ```

2. **IngÃ©nierie des caractÃ©ristiques** :
   ExÃ©cutez le script `preprocessing.py` pour nettoyer et gÃ©rer les valeurs manquantes :
   ```bash
   python scripts/preprocessing.py
   ```

3. **EntraÃ®nement du modÃ¨le** :
   ExÃ©cutez le script `pipeline.py` pour entraÃ®ner le modÃ¨le et sauvegarder les rÃ©sultats (Ã©quivalent Ã  `--start-from preprocessed`) :
   ```bash
   python scripts/pipeline.py
   ```

### Remarques

- Assurez-vous que les fichiers de donnÃ©es nÃ©cessaires (`data.csv`, `data_processed.csv`, etc.) sont prÃ©sents dans le rÃ©pertoire `data/` avant de lancer les scripts.
- Les rÃ©sultats intermÃ©diaires et finaux seront sauvegardÃ©s dans les rÃ©pertoires `data/` et `models/`.


---

## Application Streamlit

L'application Streamlit offre une interface interactive permettant d'explorer et d'analyser les Ã©missions de COâ‚‚ des voitures europÃ©ennes. Elle se compose de trois pages principales :

#### ğŸ“Š Exploration
Analyse exploratoire du jeu de donnÃ©es brut avant traitement, comprenant :
- **Taux de complÃ©tion des colonnes** : Visualisation du pourcentage de valeurs renseignÃ©es pour identifier les colonnes nÃ©cessitant un nettoyage
- **RÃ©partition des types de carburant** : Distribution des vÃ©hicules selon leur carburant pour identifier les types dominants
- **Distribution de la puissance par carburant** : DÃ©tection des outliers (vÃ©hicules de sport) qui pourraient biaiser le modÃ¨le
- **Relation cylindrÃ©e vs Ã©missions** : CorrÃ©lation entre cylindrÃ©e et COâ‚‚ avec lignes de rÃ©gression par type de carburant
- **Matrice de corrÃ©lation** : Relations linÃ©aires entre caractÃ©ristiques techniques

#### ğŸ“ˆ RÃ©sultats
Analyse comparative des modÃ¨les de prÃ©diction avec trois sections :
- **Classification K-means** : Regroupement des vÃ©hicules par caractÃ©ristiques similaires (analyse exploratoire)
- **RÃ©gression linÃ©aire vs Random Forest (avec consommation)** : Comparaison des performances et identification de la forte corrÃ©lation entre consommation et Ã©missions
- **Random Forest sans consommation** : Comparaison avec/sans feature engineering pour analyser l'influence rÃ©elle des variables techniques (cylindrÃ©e, puissance, masse, Ã¢ge)

#### ğŸ”® PrÃ©diction
Outil interactif permettant de saisir les caractÃ©ristiques d'un vÃ©hicule et d'obtenir une prÃ©diction des Ã©missions de COâ‚‚ via le modÃ¨le Random Forest entraÃ®nÃ©

Pour lancer l'application :

``` bash
streamlit run streamlit_app/app.py
```

---


## RÃ©sultats du ModÃ¨le

Le modÃ¨le Random Forest final **sans consommation de carburant** mais **avec feature engineering** a obtenu d'excellentes performances :

### MÃ©triques de Performance

| Ensemble | MSE (g/km) | RÂ² | RMSE (g/km) |
|----------|------------|-----|-------------|
| **EntraÃ®nement** | 24,05 | 0,9866 | 4,90 |
| **Validation croisÃ©e** | 34,98 | 0,9805 | 5,91 |
| **Test** | 32,70 | 0,9816 | 5,72 |

### InterprÃ©tation

Ces rÃ©sultats dÃ©montrent la capacitÃ© du modÃ¨le Ã  prÃ©dire les Ã©missions de COâ‚‚ avec une **prÃ©cision de 98,16%** sur des donnÃ©es non vues et avec une **erreur moyenne de prÃ©diction d'environ 5,7 g/km**. L'alignement entre les mÃ©triques d'entraÃ®nement et de validation indique que le modÃ¨le **gÃ©nÃ©ralise bien sans surapprentissage** significatif.

L'exclusion de la consommation de carburant permet d'analyser l'influence rÃ©elle des caractÃ©ristiques techniques (masse, cylindrÃ©e, puissance, type de carburant, Ã¢ge) sur les Ã©missions, rendant le modÃ¨le plus utile pour des analyses prÃ©dictives sur de nouveaux vÃ©hicules dont la consommation n'est pas encore connue.

### Variables les plus influentes

D'aprÃ¨s l'analyse SHAP disponible dans l'application Streamlit :
1. Type de carburant (hybride ou non)
2. Masse du vÃ©hicule
3. CylindrÃ©e du moteur
4. Puissance

### Chargement du ModÃ¨le

Le modÃ¨le entraÃ®nÃ© peut Ãªtre chargÃ© pour faire des prÃ©dictions :

``` python
import joblib

model = joblib.load('models/random_forest_model.jbl.lzma')
```

---

## Contribuer

Les contributions sont les bienvenues ! Pour contribuer :
1. Fork ce dÃ©pÃ´t.
2. CrÃ©ez une branche pour votre fonctionnalitÃ© (`git checkout -b feature/ma-nouvelle-fonctionnalite`).
3. Commitez vos modifications (`git commit -am 'Ajout d'une nouvelle fonctionnalitÃ©'`).
4. Poussez la branche (`git push origin feature/ma-nouvelle-fonctionnalite`).
5. Ouvrez une Pull Request.

---

## Licence

Ce projet est sous licence MIT. Voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.
